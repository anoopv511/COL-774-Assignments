{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data\n",
    "x_train = np.loadtxt('../data/mnist/train.csv',delimiter=',',dtype=np.float64)\n",
    "y_train = x_train[:,-1].reshape(-1,1)\n",
    "x_train = np.delete(x_train,-1,1)\n",
    "train_max, train_min = x_train.max(), x_train.min()\n",
    "x_train /= (train_max - train_min)              # Scaling\n",
    "\n",
    "# Test Data\n",
    "x_test = np.loadtxt('../data/mnist/test.csv',delimiter=',',dtype=np.float64)\n",
    "y_test = x_test[:,-1].reshape(-1,1)\n",
    "x_test = np.delete(x_test,-1,1)\n",
    "x_test /= (train_max - train_min)               # Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Classifier\n",
    "class SVM():\n",
    "    def __init__(self,maxit,maxcount,batchsize,lambda_,c=1,project=False):\n",
    "        self.maxit = maxit                  # Maximum Iterations\n",
    "        self.maxcount = maxcount            # Maximum Count for stopping training\n",
    "        self.batchsize = batchsize          # Batchsize\n",
    "        self.lambda_ = lambda_              # Hyperparameter - lambda\n",
    "        self.c = c                          # Hyperparameter - c\n",
    "        self.project = project              # Optional - Projection Step\n",
    "    \n",
    "    # fit method\n",
    "    def fit(self,x_train,y_train,printAfter=1):\n",
    "        indices = np.arange(self.batchsize)\n",
    "        self.w = np.zeros((x_train.shape[1],1))\n",
    "        self.b = 0\n",
    "        counter = 0\n",
    "        prev_cost = 0\n",
    "        for it in range(self.maxit):\n",
    "            rand_idx = np.random.randint(0,x_train.shape[0],self.batchsize)\n",
    "            sub_x, sub_y = x_train[rand_idx], y_train[rand_idx]\n",
    "            loss = sub_y*(np.dot(sub_x,self.w) + self.b)\n",
    "            cost = self.lambda_*(self.w**2).sum()/2 + self.c*loss.sum()/float(self.batchsize)\n",
    "            if(it > 0 and it%printAfter == 0): print(\"{0} - {1}\".format(it,cost))\n",
    "            counter = counter + 1 if cost > prev_cost else 0\n",
    "            prev_cost = cost\n",
    "            idx = indices[loss.ravel() < 1]\n",
    "            eta = 1/float(self.lambda_*(it+1))\n",
    "            if(counter > self.maxcount):\n",
    "                print(\"{0} - {1}\".format(it,cost))\n",
    "                break\n",
    "            self.w = self.w*(1 - self.lambda_*eta) + (self.c*eta/float(self.batchsize))*(sub_x[idx]*sub_y[idx]).sum(axis=0).reshape(-1,1)\n",
    "            self.b = (self.c*eta/float(self.batchsize))*sub_y[idx].sum()\n",
    "            if self.project:\n",
    "                self.w *= np.min(1,float(1/float(np.sqrt(lambda_*np.dot(self.w.T,self.w)))))\n",
    "            \n",
    "    # predict method\n",
    "    def predict(self,x_test,conf=False):\n",
    "        return ((np.dot(x_test,self.w) + self.b) > 0).astype(np.int64) if not conf else (np.dot(x_test,self.w) + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-vs-One Model\n",
    "def onevsone(x_train,y_train,maxit,maxcount,batchsize,lambda_,c=1,project=False,printAfter=1):\n",
    "    classifiers = []\n",
    "    labels = np.unique(y_train)\n",
    "    class_split = list(itertools.combinations(np.arange(10),2))\n",
    "    indices = np.arange(x_train.shape[0])\n",
    "    for split in class_split:\n",
    "        idx_c1 = indices[(y_train == split[0]).ravel()]\n",
    "        idx_c2 = indices[(y_train == split[1]).ravel()]\n",
    "        idx = np.concatenate((idx_c1,idx_c2))\n",
    "        sub_x, sub_y = x_train[idx], y_train[idx]\n",
    "        sub_y = (sub_y == split[0]).astype(np.int64) - (sub_y == split[1]).astype(np.int64)\n",
    "        classifier = SVM(maxit,batchsize,lambda_,c)\n",
    "        classifier.fit(sub_x,sub_y,printAfter)\n",
    "        classifiers.append((classifier,split[0],split[1]))\n",
    "    return classifiers\n",
    "\n",
    "def pred_onevsone(classifiers,x_test):\n",
    "    preds = np.zeros((x_test.shape[0],len(classifiers)))\n",
    "    ones = np.ones((x_test.shape[0],1))\n",
    "    for idx, c in enumerate(classifiers):\n",
    "        pred = c[0].predict(x_test,conf=False).reshape(-1,1)\n",
    "        preds[:,idx] = np.where(pred == 1,c[1]*ones,c[2]*ones).ravel()\n",
    "    final_pred = -stats.mode(-preds,axis=1)[0]\n",
    "    return final_pred\n",
    "\n",
    "def indv_acc_onevsone(classifiers,x_test,y_test):\n",
    "    for c in classifiers:\n",
    "        indices = np.arange(x_test.shape[0])\n",
    "        idx_c1 = indices[(y_test == c[1]).ravel()]\n",
    "        idx_c2 = indices[(y_test == c[2]).ravel()]\n",
    "        idx = np.concatenate((idx_c1,idx_c2))\n",
    "        sub_x, sub_y = x_test[idx], y_test[idx]\n",
    "        ones = np.ones((sub_x.shape[0],1))\n",
    "        pred = c[0].predict(sub_x).reshape(-1,1)\n",
    "        pred = np.where(pred == 1,c[1]*ones,c[2]*ones)\n",
    "        print(\"Accuracy for classifier b/w {0}/{1} = {2}\".format(c[1],c[2],(pred == sub_y).sum()/float(sub_y.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_one = onevsone(x_train,y_train,5000,5,100,1,1,False,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Accuracy\n",
    "pred_one_train = pred_onevsone(svm_one,x_train)\n",
    "accuracy_one_train = (pred_one_train == y_train).sum()/float(y_train.shape[0])\n",
    "print(\"One-vs-One Train Accuracy = {0}\".format(accuracy_one_train))\n",
    "# indv_acc_onevsone(svm_one,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Accuracy\n",
    "pred_one_test = pred_onevsone(svm_one,x_test)\n",
    "accuracy_one_test = (pred_one_test == y_test).sum()/float(y_test.shape[0])\n",
    "print(\"One-vs-One Test Accuracy = {0}\".format(accuracy_one_test))\n",
    "# indv_acc_onevsone(svm_one,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-vs-All Model\n",
    "def onevsall(x_train,y_train,maxit,maxcount,batchsize,lambda_,c=1,project=False,printAfter=1):\n",
    "    classifiers = []\n",
    "    labels = np.sort(np.unique(y_train))\n",
    "    for l in labels:\n",
    "        sub_x, sub_y = x_train, (y_train == l).astype(np.int64) - (y_train != l).astype(np.int64)\n",
    "        classifier = SVM(maxit,batchsize,lambda_,c)\n",
    "        classifier.fit(sub_x,sub_y,printAfter)\n",
    "        classifiers.append((classifier,l))\n",
    "    return classifiers\n",
    "        \n",
    "def pred_onevsall(classifiers,x_test):\n",
    "    preds = np.zeros((x_test.shape[0],len(classifiers)))\n",
    "    for idx, c in enumerate(classifiers):\n",
    "        preds[:,idx] = c[0].predict(x_test,conf=True).ravel()\n",
    "    final_pred = preds.argmax(axis=1).reshape(-1,1)\n",
    "    return final_pred\n",
    "\n",
    "def indv_acc_onevsall(classifiers,x_test,y_test):\n",
    "    for c in classifiers:\n",
    "        ones = np.ones((x_test.shape[0],1))\n",
    "        pred = (c[0].predict(x_test,conf=True) > 0.5).astype(np.int64)\n",
    "        pred = np.where(pred == 1,c[1]*ones,-1*ones)\n",
    "        sub_y = np.where(y_test == c[1],c[1]*ones,-1*ones)\n",
    "        print(\"Accuracy for classifier b/w {0}/Rest = {1}\".format(c[1],(pred == sub_y).sum()/float(sub_y.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_all = onevsall(x_train,y_train,5000,5,100,1,1,False,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Accuracy\n",
    "pred_all_train = pred_onevsall(svm_all,x_train)\n",
    "accuracy_all_train = (pred_all_train == y_train).sum()/float(y_train.shape[0])\n",
    "print(\"One-vs-All Train Accuracy = {0}\".format(accuracy_all_train))\n",
    "# indv_acc_onevsall(svm_all,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Accuracy\n",
    "pred_all_test = pred_onevsall(svm_all,x_test)\n",
    "accuracy_all_test = (pred_all_test == y_test).sum()/float(y_test.shape[0])\n",
    "print(\"One-vs-All Test Accuracy = {0}\".format(accuracy_all_test))\n",
    "# indv_acc_onevsall(svm_all,x_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
